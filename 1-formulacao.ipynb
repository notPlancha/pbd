{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f69b38-9b79-4911-8694-b5ca7f3609e6",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84ceeb7-01cf-4c0b-8c37-1d4fc94dfa96",
   "metadata": {},
   "source": [
    "Em primeiro lugar, vamos observar o enunciado com atenção. Se seguida está um resumo das partes importantes dele.\n",
    "\n",
    "## Contexto\n",
    "> Pretende-se que seja implementada uma solução computacional para estudo e análise de dados de grande dimensão. Nesse sentido, deverá ser contruído um modelo de análise e processamento de dados baseado em métodos e algoritmos\n",
    "lecionados nas aulas\n",
    "\n",
    "> A escolha do domínio de dados e respetico conjunto de dados a utilizar, bem [como] a formulação do próprio problema em estudo, será da responsabilidade dos autores do trabalho, [... que ...] devem ser obtidos a partr da lista de fontes especificada [...] na tabela 1\n",
    "\n",
    "Entre as opções, nós escolhemos a competição \"Predict Student Performance from Game Play\" pois parecia um tema com potencial, e parece alcançável com os métodos lecionados em aula, conforme o objetivo do projeto.\n",
    "\n",
    "## Requesitos\n",
    "> [...] requisito de utilização de Apache Spark e Python é mandatório\n",
    ">\n",
    "> [...] vão ser utilizados serviços em ambiente cloud, da Amazon para contexto académico – AWS Academy – na qual será disponibilizada uma classe de ensino para os(as) alunos(as) da unidade curricular\n",
    ">\n",
    "> Os algorimos a utilizar que estarão na base da construção do [... MAPD] devem fazer parte da plataforma Apache Spark\n",
    ">\n",
    "> A implementação da dolução deve ser [...] composta por mais do que um notebook ou módulo Python. Compete aos autores do trabalho a estruturar [...] o código implementado.\n",
    ">\n",
    "> A submissão consiste num arquivo em formato zip [...] com [...] (i) relatório e (ii) notebooks e/ou módulos Python.\n",
    ">\n",
    "> relatório deve ser um documento sucinto e em formato pdf, com o máximo de oito [8] páginas.\n",
    ">\n",
    "> O prazo de submissão é 12:00 de 8 de abril de 2023 [...].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed05dc0-8dd6-47c3-bc41-63d33fb0801d",
   "metadata": {},
   "source": [
    "Nesta secção, vamos observar os dados que temos de forma geral, e o objetivo da competição do kaggle.\n",
    "\n",
    "Conforme o enuncuiado do kaggle:\n",
    "\n",
    "> The goal of this competition is to predict student performance during game-based learning in real-time.\n",
    "\n",
    "Nós temos acesso a uma base de dados de todos os eventos de cada sessão de um utilizador, e cada sessão tem 18 questões, onde nós sabemos se a sessão acertou em cada sessão. O nosso objetivo é prever, baseado nos movimentos e nas ações de uma sessão, se essa vai acertar ou errar nas questões. Vamos chamar a essas questões $q _\\lambda, \\lambda \\in \\left[ 1, 18 \\right]$. O jogo parece apresentar 22 níveis, com 3 \"checkpoints\" de questões, um no nível 4, outro no nível 12 e o último no último nível, 22. Vamos chamar a esses níveis $n_\\lambda, \\lambda \\in \\left [1, 22\\right]$. Para cada sessão $s$, temos que prever se $s$ vai acertar na questão, baseado nas ações prévias da sessão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15cee1-d5d4-4c86-aac0-83c5d9b52cd1",
   "metadata": {},
   "source": [
    "Para entender melhor a base de dados, nós planeamos fazer dois passos:\n",
    "\n",
    "* Jogar o jogo.\n",
    "* Interpretar os dados que nos são dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4698e-5a3f-4bcf-8bf7-1a4f58da3324",
   "metadata": {},
   "source": [
    "## Jogar o jogar\n",
    "\n",
    "O jogo encontra-se em https://pbswisconsineducation.org/jowilder/play-the-game/, e tem o título de **Jo Wilder and the Capitol Case**, produzido por *PBS Winsconsin Education*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a2cee-b0e9-4019-b7dd-85d56725719a",
   "metadata": {},
   "source": [
    "## Interpretar os dados que nos são dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e450b58-634c-4e70-ba8b-587976ffb722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_kernel",
   "language": "python",
   "name": "pyspark_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
